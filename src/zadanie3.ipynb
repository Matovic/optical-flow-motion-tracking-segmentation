{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow, motion tracking, segmentation, stereo vision\n",
    "Erik Matoviƒç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#from utils import show_img, resize_img, calc_histogram_show, plt_img, equalize_hist, gamma_coorection\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse optical flow\n",
    "\n",
    "Visualize trajectories of moving objects.\n",
    "\n",
    "Optional task: Identify each object using a bounding box and count them.\n",
    "\n",
    "Use following functions: cv::goodFeaturesToTrack, cv::calcOpticalFlowPyrLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video\n",
    "video_path = '../data/archive/fourway.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# make video writer\n",
    "out = cv2.VideoWriter('..' + video_path[15:-4] + '.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShiTomasi corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "# Take first frame and find corners in it\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, \n",
    "                            maxCorners = 200,\n",
    "                            qualityLevel = 0.6,\n",
    "                            minDistance = 14,\n",
    "                            blockSize = 14 \n",
    "                            )\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frames grabbed!\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        old_gray, frame_gray, p0, None, winSize  = (15, 15),\n",
    "        maxLevel = 4, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                                  10, 0.03))\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 10, color[i].tolist(), -1)\n",
    "    img = cv2.add(frame, mask)\n",
    "    #cv2.imshow('frame', img)\n",
    "    #cv2.waitKey(0)\n",
    "    # write the flipped frame\n",
    "    out.write(img)\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense optical flow\n",
    "\n",
    "Identify moving objects in video and draw green rectangle around them.\n",
    "\n",
    "Use downsampled video for this task if necessary for easier processing.\n",
    "\n",
    "Use following functions: cv::calcOpticalFlowFarneback\n",
    "\n",
    "[OpenCV's tutorial on how to optical flow](https://docs.opencv.org/4.x/d4/dee/tutorial_optical_flow.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion tracking Datasets\n",
    "\n",
    "Feel free to experiment with multiple videos for motion tracking. Use the following link for additional datasets - https://motchallenge.net/data/MOT15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation using background subtraction\n",
    "\n",
    "Use background substraction methods to properly segment the moving objects from their background. Use one of the videos with static camera.\n",
    "\n",
    "Use the following approaches:\n",
    "\n",
    "    Accumulated weighted image\n",
    "\n",
    "    Mixture of Gaussian (MOG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Cut segmentation\n",
    "\n",
    "Propose a simple method to segment a rough estimate of lateral ventricle segmentation using morphological processing and thresholding.\n",
    "\n",
    "[Link, 5 x PNG, 137 KB](https://drive.google.com/file/d/1hnQ_PHx0LhMNCMlpwCFhXVx4fFl9j_Aq/view) \n",
    "\n",
    "Use OpenCV's graph cut method to refine segmentation boundary.\n",
    "\n",
    "cv::grabCut\n",
    "\n",
    "Input has to be BGR (3 channel)\n",
    "\n",
    "Values for the mask parameter:\n",
    "\n",
    "GC_BGD = 0 - an obvious background pixels\n",
    "\n",
    "GC_FGD = 1 - an obvious foreground (object) pixel\n",
    "\n",
    "GC_PR_BGD = 2 - a possible background pixel\n",
    "\n",
    "GC_PR_FGD = 3  - a possible foreground pixel\n",
    "\n",
    "An example of GrabCut algorithm: link (note: This example uses a defined rectangle for grabcut segmentation. In our case we want to use the mask option instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
